{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change DATA_DIR per your local filepath\n",
    "\n",
    "DATA_DIR = '/home/mandar/Data/NCSU/TropeAnalysis/TropesDataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_movie_list(genre: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    This function returns all the json filenames containing movie dialogs\n",
    "    Args:\n",
    "        genre (str): String containing genre name.\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of strings containing json filenames.\n",
    "    \"\"\"\n",
    "    movie_genre_json_list = []\n",
    "    movies_per_genre = os.listdir(join(DATA_DIR, 'ScreenPy', 'ParserOutput', genre))\n",
    "    for movie in movies_per_genre:\n",
    "        if movie.endswith('.json'):\n",
    "            movie_genre_json_list.append(movie)\n",
    "    return movie_genre_json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_movie_dialog_file(genre: str, movie_filename: str) -> List[List[Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    Loads the json data contained in movie file:\n",
    "    Args:\n",
    "        genre (str): String containing genre name.\n",
    "        movie_filename (str): String containing movie filename.\n",
    "    \n",
    "    Returns:\n",
    "        List[List[Dict[str]]]: List of lists with each nested list containing a dictionary.\n",
    "    \"\"\"\n",
    "    with open(join(DATA_DIR, 'ScreenPy', 'ParserOutput', genre, movie_filename), 'r') as f:\n",
    "        movie_dialog_json = json.loads(f.read())\n",
    "    return movie_dialog_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_movie_dialog_data(movie_json_data: List[List[Dict[str, str]]], \n",
    "                            verbose: bool = False):\n",
    "    \"\"\"\n",
    "    This function parses the movie json data, and collects the following information,\n",
    "        1. Unique characters with dialogs\n",
    "        2. Number of dialogs per character\n",
    "        3. Dialogs of all characters concatenated into a string\n",
    "    Args:\n",
    "        movie_json_data (List[List[Dict[str, str]]]): Json data containing movie character names and dialogs.\n",
    "        verbose (bool): Boolean indicating whether raw dialogs should be printed.\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: Dictionary with movie name as key and various nested dictionaries \n",
    "        containing data mentioned in function description.\n",
    "    \"\"\"\n",
    "    movie_characters = set()\n",
    "    movie_dialogs = list()\n",
    "    dialogs_per_character = defaultdict(int)\n",
    "    movie_info_dict = defaultdict()\n",
    "    for scene_dialogs in movie_json_data:\n",
    "        for dialog_info in scene_dialogs:\n",
    "            if 'speaker/title' in dialog_info['head_text']:\n",
    "                dialog_speaker = dialog_info['head_text']['speaker/title']\n",
    "                if verbose:\n",
    "                    print(f\"Speaker: {dialog_speaker}\")\n",
    "                    print(dialog_info['text'])\n",
    "                character = dialog_speaker.split('(')[0].strip()\n",
    "                movie_characters = movie_characters.union([character])\n",
    "                dialogs_per_character[character] += 1\n",
    "                movie_dialogs.append(dialog_info['text'])\n",
    "\n",
    "    movie_info_dict['characters'] = movie_characters\n",
    "    movie_info_dict['actor_dialog_count'] = dialogs_per_character\n",
    "    movie_info_dict['dialogs'] = ' '.join(movie_dialogs)\n",
    "    return movie_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = 'Action'\n",
    "genre_movie_json_list = get_genre_movie_list(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avatar.json',\n",
       " 'dune.json',\n",
       " 'blade.json',\n",
       " 'machete.json',\n",
       " 'startrekfirstcontact.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_movie_json_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(DATA_DIR, 'films_tropes_20190501.json'), 'rb') as file:\n",
    "    tvtropes_json_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tvtropes_json_dict[action_movie_script_trope_df.Movie_trope[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = [movie.split('.json')[0] for movie in genre_movie_json_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_movie_script_trope_df = pd.read_csv(join(DATA_DIR, 'action_movie_script_trope_match.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find movies that have tropes\n",
    "movie_match_df = action_movie_script_trope_df.loc[action_movie_script_trope_df.Movie_Script.isin(movie_list)].copy()\n",
    "len(movie_match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_movie_dialogs = defaultdict()\n",
    "all_preprocess_movie_dialogs = defaultdict()\n",
    "movie_trope_dict = defaultdict()\n",
    "\n",
    "for movie_row in movie_match_df.iterrows():\n",
    "    movie = movie_row[1].Movie_Script\n",
    "    movie_filename = movie + '.json'\n",
    "    movie_json_data = load_json_movie_dialog_file(genre, movie_filename)\n",
    "    # Parse movie dialogs and preprocess text\n",
    "    all_movie_dialogs[movie] = parse_movie_dialog_data(movie_json_data)\n",
    "    all_preprocess_movie_dialogs[movie] = simple_preprocess(all_movie_dialogs[movie]['dialogs'])\n",
    "    \n",
    "    # Collect list of tropes for the movie\n",
    "    movie_trope_dict[movie] = tvtropes_json_dict[movie_row[1].Movie_trope]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 263)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_trope_dict), len(all_preprocess_movie_dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all unique tropes\n",
    "unique_tropes_set = list()\n",
    "for tropes in movie_trope_dict.values():\n",
    "    unique_tropes_set += list(set(tropes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tropes_count_dict = Counter(unique_tropes_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "min_trope_count = 35\n",
    "tropes_subset_list = list()\n",
    "for trope, count in tropes_count_dict.items():\n",
    "    if count > min_trope_count:\n",
    "        tropes_subset_list.append(trope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tropes_subset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avengersthe2012 has no tropes in json file\n"
     ]
    }
   ],
   "source": [
    "movie_tropes_subset_dict = defaultdict()\n",
    "for movie, trope in movie_trope_dict.items():\n",
    "    movie_tropes_subset_dict[movie] = list(set(tropes_subset_list).intersection(set(trope)))\n",
    "    if len(movie_tropes_subset_dict[movie]) == 0:\n",
    "        print(f'{movie} has no tropes in json file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Doc2Vec model on Movie Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(all_preprocess_movie_dialogs.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_output = MultiLabelBinarizer()\n",
    "y = multi_output.fit_transform(list(movie_tropes_subset_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 262\n"
     ]
    }
   ],
   "source": [
    "documents.pop(np.where(y.sum(axis=1)==0)[0][0])\n",
    "y = y[y.sum(axis=1) > 0]\n",
    "print(len(documents), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_docs, X_test_docs, y_train, y_test = train_test_split(documents, y, \n",
    "                                                              train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 66, (196, 110), (66, 110))"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_docs), len(X_test_docs), y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = [10, 20, 50, 100, 200, 250, 300]\n",
    "window_size = [2, 5, 7, 10]\n",
    "epochs = [10, 20, 30]\n",
    "\n",
    "for v in vector_size:\n",
    "    for w in window_size:\n",
    "        for e in epochs:\n",
    "            model = Doc2Vec(X_train_docs, vector_size=v, window=w, min_count=5, \n",
    "                            epochs=e)\n",
    "            X_train_doc_vectors = []\n",
    "            X_test_doc_vectors = []\n",
    "\n",
    "            for i in range(len(X_train_docs)):\n",
    "                X_train_doc_vectors.append(model.docvecs[i])\n",
    "\n",
    "            for i in range(len(X_test_docs)):\n",
    "                X_test_doc_vectors.append(model.infer_vector(X_test_docs[i][0]))\n",
    "            X_train_doc_vectors = pd.DataFrame(X_train_doc_vectors)\n",
    "            X_test_doc_vectors = pd.DataFrame(X_test_doc_vectors)\n",
    "\n",
    "            _fit = RandomForestClassifier(n_estimators=50)\n",
    "            model = MultiOutputClassifier(estimator=_fit)\n",
    "            model.fit(X_train_doc_vectors, y_train)\n",
    "            \n",
    "            y_hat = model.predict(X_test_doc_vectors)\n",
    "\n",
    "            auc_class = np.zeros(len(y_test[0]))\n",
    "\n",
    "            for i in range(len(y_test[0])):\n",
    "                auc_class[i] = roc_auc_score(y_test[:, i],y_hat[:, i])\n",
    "            \n",
    "            print(f'Vector size: {v}, Window size: {w}, Epoch: {e}')\n",
    "            print(f'Mean AUC: {np.mean(auc_class)}, Min AUC: {np.min(auc_class)}, Max AUC: {np.max(auc_class)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data using 2-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.score(X_train_doc_vectors, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49953174225380487, 0.45013979496738116, 0.5384615384615384)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
